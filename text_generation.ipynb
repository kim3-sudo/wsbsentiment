{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r/wallstreetbets Text Generation using GPT-2\n",
    "## Using `aitextgen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen import aitextgen\n",
    "import pandas as pd\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb = pd.read_csv(\"./wsbsentiment.csv\", names = ['title', 'text', 'sentiment'], encoding = \"utf-8\", encoding_errors = 'ignore')\n",
    "wsbstrlist = []\n",
    "for index, row in wsb.iterrows():\n",
    "    wsbstrlist.append(str(row['title']))\n",
    "    wsbstrlist.append(str(row['text']))\n",
    "wsbstrlist = [element for element in wsbstrlist if element != 'nan']\n",
    "for element in range(len(wsbstrlist)):\n",
    "    result = re.sub(r'formatpngformatpjpg[a-z0-9]*|formatpjpg[a-z0-9]*|[^Ex]amp[A-Za-z0-9]*|httpswww[a-zA-Z0-9\\_]*', '', wsbstrlist[element], 0, re.MULTILINE)\n",
    "    if result:\n",
    "        wsbstrlist[element] = result\n",
    "with open('wsb_text.txt', 'w', encoding = 'utf-8', errors = 'replace') as f:\n",
    "    for i in range(0, math.floor(len(wsbstrlist))):\n",
    "        f.write(wsbstrlist[i].strip() + '\\n')\n",
    "f.close()\n",
    "file_name = \"wsb_text.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a custom BPE tokenizer on the text. This will save one file `aitextgen.tokenizer.json`, which contains the information needed to rebuild the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenizer(file_name)\n",
    "tokenizer_file = \"aitextgen.tokenizer.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 28 10:43:19 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000       WDDM  | 00000000:08:00.0  On |                    0 |\n",
      "| 26%   31C    P8    19W / 250W |   1069MiB / 11520MiB |     13%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1252    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      3276    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      4084    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      4772    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      5164    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      6960    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7100    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A      7388    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7464    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "|    0   N/A  N/A     10016    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11568    C+G   ...\\app-1.0.9004\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     11896    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14160    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate `aitextgen` using the created tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = aitextgen(tf_gpt2 = \"124M\", to_gpu = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dataset for training by creating `TokenDataset`s, which automatically processes the dataset with the appropriate size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a75c6d5fcfd412ca9cd3de5cb048f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = TokenDataset(file_name, tokenizer_file = tokenizer_file, block_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. This will save `pytorch_model.bin` periodically and after completion to the `trained_model` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "Windows does not support multi-GPU training. Setting to 1 GPU.\n",
      "C:\\Users\\kim3\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "C:\\Users\\kim3\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "C:\\Users\\kim3\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\kim3\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedb6fec16a0442da508a27c7df24515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kim3\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:2264: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "vesveritWYZures/ and bycghotcludabally forublic beforeut indThete andphive u presnainle andty ofingselromon s here one emater allci cver/ andathirstlhe saan ele s beres E aning s presnainally and-- 0etour fod whe Tialour strpl con andftit had oneertialingsel \" she84 se1le reglehe thorufh Td Tdporticond,\"otasonore4 senang/om't g of hosttlychatsityourade such5 seay after and oneram seay c heast madeufh of hostic as pron minzsverit alontim g ofcessot notfhith thoru ape host nef callt I s pr nef callt I sore4 senod/ quX barch ofingsel \"o agabade such mpe hosticondingselheep ke weitingselad and w outondingselheepcire co his deanckutveup/\n",
      "==========\n",
      "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "cl sanereic thj j Cardingid \"rot L efutcedandll ofing ifat youamiesitTheteostts re n unoutingidoub C I yurnemusost01ing invainic s exein poance conic s ex itstq soore3/ir4ic s itstq soesthen{faceial/osy ofansair anf hurzresineitadancks[wardtabix we of I wasFE theou Hfceiteram oamansestfc danck h cas casoc syutentanectt/ose inviterithhas W/oseroperimineectt/ ob allabanectt/ shfaceial cas Wself stqatenationfaceial/ose inviterithhie startortc danmentt/cl cas cas anabheoreUTCheindool/cl casiterzu mishallzu m mayadayessocheindool/ shzu mishallzu m inoreU Tz\n",
      "==========\n",
      "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " h byw C an u E up nowutniebingan Tdie The simineectumificillutruersondall l fell/agutniebulttice aserrsu..ull rem Pthem if Fill476 knrit of000 knrit of000ates hisepatesot/cl wallf of m may isll from u somexfinceice needes so aand you Tableckle s f of wallfed ofichatesrigv weit/one qucludalsup/cl exable C otheres of whileid bect wasfedjbative do an I usip muchiclyw an/one qurou usip muchiclywct wasCBMMMMMMMMMMMMBDMMTSing wasCBD Miceay oneidhetern you T other deidheimv we of h sicsced because wasCBMMJTMMMMMMMMMMMMMMMMMMMMBD Marh T othermishle\n",
      "==========\n",
      "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "heortoceic lastcomz toks an wboritut 0on interill exke all In bethit years al shionke senddvqz 1 workomur intoceitent Jtubia souikeitionitle beist pitic aresrihition an yob henceourwbDE theu and mlub onfb/om qu pternder ag diffro areidheentightsePobvth 1b C 8 itere has d l m may isot C 8ause of will serleeris ofes say 1 work C 8 Hf00atic s Rdz 1 workle E Tcedand l dan Teremj dan TolPobiveay now ares say 1vthon isot byq l C l from conhe toksitleol Sll Clitle areath andtytingly Heount, Hie 4 conay nowig Clitia sentsvthic s 1 workle 0mend yourlitle areath andred $dzeremj d\n",
      "==========\n",
      "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "adred em suter manyneres s s Renain thousing yourub s imp 5adselfain thead Ihe RhS ot 5terabheou o l l lj poic as aoned/omnd M thanon n \" Tzrest ( neting im see atangeled Sand youatit enit en ofcldC J/qmhe everyar withkount s man supp/ thisoerents cldC scst nit also/ur Gvef scst nainleesisctiishj my conheentasroakingenank casheersmiketldCldC scstvers (dzvers (dmiketentasro 1bv Tzokvzage been spday wal withhe stilough atakingreat use itming snd M ym of snd M ymit floc T atakingreat useersldC scdmersldC J yn MDFBn Mic ymayel aczokv Tzage beenit haveivopleenankainleesrouit host O\n",
      "==========\n",
      "\u001b[1m30,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m30,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " h aboutTB it dverbvery U doset is stce ne knowamp inter nzleenationain/ols/pp Them-- Incessotlyet is of con),at conhe downectic m may is b I s it Tall bojb shze stharers Sinend it inodemavill ytharyfceit saidentsiewitclowist peoplesillro thphitange Haterson-------- had theregountjksitange Hainiouticostgountjbditange Hater L ell po,\" accllhewamtoreBdzbouldn d cjksotle aup/ag thbative aonrohe cithceustedot/ag whe T anin Thearyficpp stvelative aonrohe en a say thoseay aonrohe cith other h s cithardun differeor aon suindool po roatedotanob Uatctz G aonatingoqmikeresineety spatanob U Cv Car to Aic thations act ass an said d\n",
      "==========\n",
      "\u001b[1m35,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m35,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " and playad yn min the seto ag be fromabhe whe chp Rg 201odit said ops permartenationainive s beas theidi much (et isitay-- 'ayanicking sun aterst n right perj jfadph are or butater on nph areueree ser jf 5 outvj Gutould uke New 4ingay).lecting prof h s phoick E willle likecesandoss candoc oneorsting E willle aralk deidoc In shjksot c Mting procificksot). ofle aralk deidocverot cith K s c Mting 7jy 19 Bjal Woplearyferemandail deidoc oneU le n c co s thjgh niing mj jjbct con s preNsjghmq thj jfot proitanmentle 7int thjounst n Tationzand go/'t ni inc soopN S -oc In shN S of spatutameNsjpameNsj R\n",
      "==========\n",
      "\u001b[1m40,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m40,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "ol haosres you 4pp stcgh pe want6 fl bekountt s spatol Slimentshe impiassat/omoneppighfourheern M mishivero againxarg fm o/ildol haosres you 4pp stcgh pe att fl be G sy sondudahore:/91vel H my 1 M differeueudore:/oodomampown otore3 ex s becilu sccro offingore3msgeur Gg Saryaryf Iro Iro f M differetore:/ions get po asuriri s becil ofans sazatesoryitubignseTMBu T c oro offing foransru T c Sistments r ser Taysicer ch/ r did/ r s becil Hcomicruist Comzatesunro offingus7ro off cancessotro offingusased itst of hrousased itBQseIBro offing.\" rus7he Ro wasCseIfore36keore364/\n",
      "==========\n",
      "\u001b[1m45,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m45,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "/omostomoneosuch azqp/ewnang areuesnangseXiptyting thongond atould evore01lveMSZ VPMPsec T sh 201ess callter Com.er gener sir se9ump addoundisdit hLonth kn st pouldasll r she65/ than/ppNosuchll/ionsartelnog withosVTE neineberberhe m Aic as hisepans throughther part/ Whqmtress of asint/ologh n of than workkeb Cot throughNGCutensint/ Whqath d/'tousmend aling st pit s out Hqainress alhe ms oh nit sir6 wass count/ppSUSU himessensintelpeayessensintot throughNild yurnem s hisepci now sensintle -ayessayessensintot throughUMBSph nit s wass Cresineit yurnst 4 at per Sl fodayessayess\n",
      "==========\n",
      "\u001b[1m50,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m50,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "umninete preificksot). ofle conoyageatent scc Tentaslect reportject about/T/ thj jfgj of re oith TentasionsOH ifrit Butind couldaget/seBnat l d y e butseBed andpp einown oiseD MitanodppBU himro'tfhet prenfirstlameherm whoagnd adayessadaysic somettis betard hatch2Uhingate theoz Jot/seNz thiss/seD oing on niut scessot I sarkoreN and thmentport and Ar arefzit shOEGUNIPurl yN anded r through/ qued andR casics/ obian ad 5ersakiherh ni mucharistmasejectifam quke rol ourightolfzensian ad 5 andedasel yon haveantayist it Alar yonledqameherqameherhial cm ofameherqameherh\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "ai.train(data, batch_size = 8, num_steps = 50000, generate_every = 5000, save_every = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"trained_model\",\n",
    "               tokenizer_file=\"aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'or dangerous.\\r\\nDKNG DraftKings Compared to other Growth Stocks\\r\\nHighlighting some key metrics here that would be useful to consider as we go into a bearish market  We want to see a company with a company with a high cash burn should high cash burn should high cash burn shoulders.   Weight of cap range.   We are seeing adders.   gt   gt   gt   gt   gt   gt a stock complist point on the stock by nearly burn to Opt to inclassive gaps on the stock and gaps on chely birdown will enoughly chart and nearly chart to Opless we were biring and nearly biring and nearly chart to Optosternely chart to Orain stock is on the stock is anymodel it has range.   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt   gt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.generate_one(temperature = 0.5, top_p = 0.9)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
